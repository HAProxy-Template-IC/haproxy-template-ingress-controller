stages:
  - lint
  - test
  - build
  - integration
  - deploy

# Prevent duplicate pipelines for MR and branch pushes
workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS
      when: never
    - if: $CI_COMMIT_BRANCH
    - if: $CI_COMMIT_TAG

variables:
  # Language and tool versions
  # renovate: datasource=docker depName=golang
  GO_VERSION: "1.25"
  # renovate: datasource=docker depName=docker
  DOCKER_VERSION: "29"
  # renovate: datasource=docker depName=python
  PYTHON_VERSION: "3.14"
  # renovate: datasource=github-releases depName=kubernetes-sigs/kind
  KIND_VERSION: "0.31.0"
  # renovate: datasource=docker depName=kindest/node
  KIND_NODE_VERSION: "v1.35.0"
  # Container registry
  CI_REGISTRY_IMAGE: registry.gitlab.com/haproxy-template-ic/haproxy-template-ingress-controller
  # Coverage packages (excludes generated code) - keep in sync with Makefile
  COVERAGE_PACKAGES: "./cmd/...,./pkg/controller/...,./pkg/core/...,./pkg/dataplane/...,./pkg/events/...,./pkg/httpstore/...,./pkg/introspection/...,./pkg/k8s/...,./pkg/lifecycle/...,./pkg/metrics/...,./pkg/templating/...,./pkg/webhook/..."
  # Chart testing tool versions
  # renovate: datasource=github-releases depName=helm/chart-testing
  CT_VERSION: "3.14.0"
  # renovate: datasource=github-releases depName=helm-unittest/helm-unittest
  HELM_UNITTEST_VERSION: "1.0.3"
  # renovate: datasource=github-releases depName=yannh/kubeconform
  KUBECONFORM_VERSION: "0.7.0"
  # renovate: datasource=pypi depName=yamllint
  YAMLLINT_VERSION: "1.37.1"
  # markdownlint-cli2 pinned to 0.14.0 - newer versions require Node.js 20+
  MARKDOWNLINT_VERSION: "0.14.0"
  # renovate: datasource=github-releases depName=goreleaser/goreleaser
  GORELEASER_VERSION: "2.13.1"
  # renovate: datasource=github-releases depName=sigstore/cosign
  COSIGN_VERSION: "2.6.1"
  # CI images - HAProxy 3.2 for single-run jobs, versioned for matrix jobs
  CI_IMAGE: ${CI_REGISTRY_IMAGE}/ci:go${GO_VERSION}-haproxy3.2-docker${DOCKER_VERSION}-kind${KIND_VERSION}-ct${CT_VERSION}-unittest${HELM_UNITTEST_VERSION}-kubeconform${KUBECONFORM_VERSION}-yamllint${YAMLLINT_VERSION}-mdlint${MARKDOWNLINT_VERSION}-gr${GORELEASER_VERSION}-cs${COSIGN_VERSION}
  CI_IMAGE_VERSIONED: ${CI_REGISTRY_IMAGE}/ci:go${GO_VERSION}-haproxy${HAPROXY_VERSION}-docker${DOCKER_VERSION}-kind${KIND_VERSION}-ct${CT_VERSION}-unittest${HELM_UNITTEST_VERSION}-kubeconform${KUBECONFORM_VERSION}-yamllint${YAMLLINT_VERSION}-mdlint${MARKDOWNLINT_VERSION}-gr${GORELEASER_VERSION}-cs${COSIGN_VERSION}

# Reusable rules for path-based filtering
.rules-code:
  rules:
    - changes:
        - "**/*.go"
        - go.mod
        - go.sum
        - .tool-versions
        - Makefile
        - Dockerfile
        - scripts/**
        - .gitlab-ci.yml
        - .golangci.yml
        # Config files (ensures lint job runs for config-only changes)
        - "**/*.yaml"
        - "**/*.yml"
        - "**/*.json"
        - "**/*.md"
        - .markdownlint-cli2.jsonc

.rules-helm:
  rules:
    - changes:
        - charts/**
        - .gitlab-ci.yml

.rules-docs:
  rules:
    - changes:
        - docs/**
        - charts/**/docs/**
        - charts/**/mkdocs.yml
        - .gitlab-ci.yml

# Jobs that only run on MRs (skip main branch and tags)
# Use when tests already passed in MR and don't need to re-run on merge
.rules-mr-only:
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: never
    - if: $CI_COMMIT_TAG
      when: never

# HAProxy version matrix for multi-version testing
.haproxy-version-matrix:
  parallel:
    matrix:
      - HAPROXY_VERSION: ["3.0", "3.1", "3.2"]

# Docker-in-Docker base configuration for jobs that need to run Docker commands
# (e.g., kind clusters, docker build). In GitLab CI, the Docker daemon runs in
# a separate container (docker:dind service) accessible via the "docker" hostname.
.docker-dind:
  services:
    - name: docker:${DOCKER_VERSION}-dind
      alias: docker
  variables:
    DOCKER_DRIVER: overlay2
    DOCKER_TLS_CERTDIR: "/certs"
    DOCKER_TLS_VERIFY: "1"
    DOCKER_CERT_PATH: "/certs/client"
    DOCKER_HOST: tcp://docker:2376
  tags:
    - saas-linux-xlarge-amd64
  retry:
    max: 2
    when: runner_system_failure

# =============================================================================
# CI Image Builds (.pre stage - runs before all other stages)
# =============================================================================

.build-ci-image:
  stage: .pre
  image:
    name: moby/buildkit:rootless
    entrypoint: [""]
  variables:
    BUILDKITD_FLAGS: --oci-worker-no-process-sandbox
  tags:
    - saas-linux-medium-amd64
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: never
    - if: $CI_COMMIT_TAG
      when: never
    - changes:
        - .gitlab/ci/images/**
        - .gitlab-ci.yml
  before_script:
    - mkdir -p ~/.docker
    - echo "{\"auths\":{\"$CI_REGISTRY\":{\"username\":\"$CI_REGISTRY_USER\",\"password\":\"$CI_REGISTRY_PASSWORD\"}}}" > ~/.docker/config.json

build-ci:
  extends:
    - .build-ci-image
    - .haproxy-version-matrix
  script:
    - |
      CI_IMAGE="${CI_REGISTRY_IMAGE}/ci:go${GO_VERSION}-haproxy${HAPROXY_VERSION}-docker${DOCKER_VERSION}-kind${KIND_VERSION}-ct${CT_VERSION}-unittest${HELM_UNITTEST_VERSION}-kubeconform${KUBECONFORM_VERSION}-yamllint${YAMLLINT_VERSION}-mdlint${MARKDOWNLINT_VERSION}-gr${GORELEASER_VERSION}-cs${COSIGN_VERSION}"
      buildctl-daemonless.sh build \
        --frontend dockerfile.v0 \
        --local context=.gitlab/ci/images/ci/ \
        --local dockerfile=.gitlab/ci/images/ci/ \
        --opt build-arg:GO_VERSION=${GO_VERSION} \
        --opt build-arg:HAPROXY_VERSION=${HAPROXY_VERSION} \
        --opt build-arg:DOCKER_VERSION=${DOCKER_VERSION} \
        --opt build-arg:KIND_VERSION=${KIND_VERSION} \
        --opt build-arg:CT_VERSION=${CT_VERSION} \
        --opt build-arg:HELM_UNITTEST_VERSION=${HELM_UNITTEST_VERSION} \
        --opt build-arg:KUBECONFORM_VERSION=${KUBECONFORM_VERSION} \
        --opt build-arg:YAMLLINT_VERSION=${YAMLLINT_VERSION} \
        --opt build-arg:MARKDOWNLINT_VERSION=${MARKDOWNLINT_VERSION} \
        --opt build-arg:GORELEASER_VERSION=${GORELEASER_VERSION} \
        --opt build-arg:COSIGN_VERSION=${COSIGN_VERSION} \
        --import-cache type=registry,ref=${CI_IMAGE} \
        --export-cache type=inline \
        --output type=image,name=${CI_IMAGE},push=true

build-python-docs:
  extends: .build-ci-image
  script:
    - |
      buildctl-daemonless.sh build \
        --frontend dockerfile.v0 \
        --local context=.gitlab/ci/images/python-docs/ \
        --local dockerfile=.gitlab/ci/images/python-docs/ \
        --opt build-arg:PYTHON_VERSION=${PYTHON_VERSION} \
        --import-cache type=registry,ref=${CI_REGISTRY_IMAGE}/ci/python-docs:latest \
        --export-cache type=inline \
        --output type=image,name=${CI_REGISTRY_IMAGE}/ci/python-docs:latest,push=true

# =============================================================================
# Lint Stage
# =============================================================================

lint:
  stage: lint
  image: ${CI_IMAGE}
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: never
    - if: $CI_COMMIT_TAG
      when: never
    - when: on_success
  tags:
    - saas-linux-medium-amd64
  interruptible: true
  needs:
    - job: build-ci
      optional: true
  before_script:
    - go version
  script:
    - make lint
  artifacts:
    reports:
      codequality: gl-code-quality-report.json
    expire_in: 1 week
    when: always

audit:
  stage: lint
  image: ${CI_IMAGE}
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: never
    - if: $CI_COMMIT_TAG
      when: never
    - !reference [.rules-code, rules]
  tags:
    - saas-linux-medium-amd64
  interruptible: true
  needs:
    - job: build-ci
      optional: true
  script:
    - make audit

# Check Go API compatibility with previous releases
# Uses golang.org/x/exp/cmd/gorelease to validate SemVer compliance
api-compatibility:
  stage: lint
  image: ${CI_IMAGE}
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: never
    - if: $CI_COMMIT_TAG
      when: never
    - !reference [.rules-code, rules]
  tags:
    - saas-linux-small-amd64
  interruptible: true
  needs:
    - job: build-ci
      optional: true
  allow_failure: false
  script:
    - |
      # Find the latest controller release tag
      LATEST_TAG=$(git tag -l 'haptic-controller-v*' --sort=-v:refname | head -1)
      if [ -z "$LATEST_TAG" ]; then
        echo "No previous release found, skipping API compatibility check"
        exit 0
      fi
      echo "Checking API compatibility against ${LATEST_TAG}..."
      # Extract version without haptic-controller- prefix for gorelease
      BASE_VERSION=${LATEST_TAG#haptic-controller-}
      go run golang.org/x/exp/cmd/gorelease@latest -base=${BASE_VERSION}

chart-test:
  stage: lint
  image: ${CI_IMAGE}
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: never
    - if: $CI_COMMIT_TAG
      when: never
    - !reference [.rules-helm, rules]
  tags:
    - saas-linux-medium-amd64
  interruptible: true
  needs:
    - job: build-ci
      optional: true
  script:
    - make lint-chart-ci KUBE_VERSION="${KIND_NODE_VERSION#v}"
  artifacts:
    reports:
      junit: chart-test-results.xml
    expire_in: 1 week
    when: always

# =============================================================================
# Test Stage
# =============================================================================

test:
  stage: test
  image: ${CI_IMAGE}
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: never
    - if: $CI_COMMIT_TAG
      when: never
    - !reference [.rules-code, rules]
  tags:
    - saas-linux-large-amd64
  interruptible: true
  needs:
    - job: build-ci
      optional: true
  before_script:
    - haproxy -v
  script:
    # gotestsum passes coverage flags through to go test - single test run
    # Use -coverpkg to exclude generated code from coverage calculation
    - |
      go tool gotestsum --junitfile report.xml --format testname -- \
        -race -coverprofile=coverage.out -covermode=atomic \
        -coverpkg=${COVERAGE_PACKAGES} \
        ./...
    # Show coverage summary (combined coverage is reported by coverage-combined job)
    - go tool cover -func=coverage.out | tail -1
    # Note: Cobertura report is generated by coverage-combined job which merges unit + integration
  artifacts:
    paths:
      - coverage.out
    reports:
      junit: report.xml
    expire_in: 1 week
    when: always

.validate-helm-libraries-base:
  stage: test
  image: ${CI_IMAGE_VERSIONED}
  tags:
    - saas-linux-medium-amd64
  interruptible: true
  needs:
    - job: build-ci
      optional: true
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: never
    - if: $CI_COMMIT_TAG
      when: never
    - changes:
        - "**/*.go"
        - go.mod
        - go.sum
        - charts/**
        - .gitlab-ci.yml
  before_script:
    - haproxy -v
  script:
    - make build
    - |
      helm template charts/haptic \
        --api-versions=gateway.networking.k8s.io/v1/GatewayClass \
        --set controller.templateLibraries.ingress.enabled=true \
        --set controller.templateLibraries.gateway.enabled=true \
        --set controller.templateLibraries.haproxytech.enabled=true \
        | yq 'select(.kind == "HAProxyTemplateConfig")' \
        > /tmp/merged-config.yaml
      ./bin/haptic-controller validate -f /tmp/merged-config.yaml

validate-helm-libraries:
  extends:
    - .validate-helm-libraries-base
    - .haproxy-version-matrix

# =============================================================================
# Build Stage
# =============================================================================

# Compile Go binary using CI image with cached modules
# Separate compilation allows using Go module cache effectively
compile:
  stage: build
  image: ${CI_IMAGE}
  rules:
    - if: $CI_COMMIT_TAG
      when: never
    - !reference [.rules-code, rules]
  tags:
    - saas-linux-2xlarge-amd64
  interruptible: true
  needs:
    - job: build-ci
      optional: true
  script:
    - |
      CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build \
        -trimpath \
        -buildvcs=false \
        -ldflags="-s -w -X main.version=ci-${CI_PIPELINE_ID} -X main.commit=${CI_COMMIT_SHA}" \
        -o haptic-controller \
        ./cmd/controller
  artifacts:
    paths:
      - haptic-controller
    expire_in: 1 hour

# Package pre-built binary into Docker image for each HAProxy version
# Uses Dockerfile's named build context feature to override the 'binary' stage
build-test-image:
  stage: build
  image:
    name: moby/buildkit:rootless
    entrypoint: [""]
  extends:
    - .haproxy-version-matrix
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: never
    - if: $CI_COMMIT_TAG
      when: never
    - !reference [.rules-code, rules]
  tags:
    - saas-linux-medium-amd64
  needs:
    - compile
  variables:
    BUILDKITD_FLAGS: --oci-worker-no-process-sandbox
  before_script:
    - mkdir -p ~/.docker
    - echo "{\"auths\":{\"$CI_REGISTRY\":{\"username\":\"$CI_REGISTRY_USER\",\"password\":\"$CI_REGISTRY_PASSWORD\"}}}" > ~/.docker/config.json
  script:
    - |
      TEST_IMAGE="${CI_REGISTRY_IMAGE}:ci-${CI_PIPELINE_ID}-haproxy${HAPROXY_VERSION}"
      # Create binary context with pre-compiled controller
      mkdir -p binary-context
      cp haptic-controller binary-context/haptic-controller
      # Build using named context override - 'binary' stage uses our pre-built binary
      buildctl-daemonless.sh build \
        --frontend dockerfile.v0 \
        --local context=. \
        --local dockerfile=. \
        --local binary=binary-context \
        --opt context:binary=local:binary \
        --opt target=runtime \
        --opt build-arg:HAPROXY_VERSION=${HAPROXY_VERSION} \
        --output type=image,name=${TEST_IMAGE},push=true

# =============================================================================
# Integration Stage
# =============================================================================

.test-integration-base:
  stage: integration
  image: ${CI_IMAGE_VERSIONED}
  extends:
    - .docker-dind
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: never
    - if: $CI_COMMIT_TAG
      when: never
    - !reference [.rules-code, rules]
  timeout: 30 minutes
  interruptible: true
  needs:
    - job: build-ci
      optional: true
  variables:
    KEEP_CLUSTER: "false"
  script:
    - mkdir -p coverage
    - |
      go tool gotestsum --junitfile report-integration.xml --format testname -- \
        -tags=integration -race -timeout 15m \
        -coverprofile=coverage/integration-${HAPROXY_VERSION}.out -covermode=atomic \
        -coverpkg=${COVERAGE_PACKAGES} \
        ./tests/integration/...
  artifacts:
    paths:
      - coverage/
    reports:
      junit: report-integration.xml
    when: always
    expire_in: 1 week

test-integration:
  tags:
    - saas-linux-2xlarge-amd64
  extends:
    - .test-integration-base
    - .haproxy-version-matrix

# Combined unit + integration coverage report (merges all HAProxy version coverage files)
coverage-combined:
  stage: integration
  image: ${CI_IMAGE}
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: never
    - if: $CI_COMMIT_TAG
      when: never
    - !reference [.rules-code, rules]
  tags:
    - saas-linux-medium-amd64
  interruptible: true
  needs:
    - job: build-ci
      optional: true
    - job: test
      artifacts: true
    - job: "test-integration: [3.0]"
      artifacts: true
    - job: "test-integration: [3.1]"
      artifacts: true
    - job: "test-integration: [3.2]"
      artifacts: true
  script:
    - mkdir -p coverage
    - cp coverage.out coverage/unit.out
    - |
      echo "Unit test coverage:"
      go tool cover -func=coverage/unit.out | tail -5
    - |
      echo "Integration test coverage (HAProxy 3.0):"
      go tool cover -func=coverage/integration-3.0.out | tail -5
    - |
      echo "Integration test coverage (HAProxy 3.1):"
      go tool cover -func=coverage/integration-3.1.out | tail -5
    - |
      echo "Integration test coverage (HAProxy 3.2):"
      go tool cover -func=coverage/integration-3.2.out | tail -5
    - |
      echo "Merging coverage profiles..."
      go run github.com/wadey/gocovmerge@latest \
        coverage/unit.out \
        coverage/integration-3.0.out \
        coverage/integration-3.1.out \
        coverage/integration-3.2.out \
        > coverage/combined.out
    - |
      echo "Combined coverage:"
      go tool cover -func=coverage/combined.out | tail -1
    # Convert combined coverage to Cobertura for GitLab diff visualization
    - gocover-cobertura < coverage/combined.out > coverage/combined.xml
  coverage: '/total:\s+\(statements\)\s+(\d+\.\d+)%/'
  artifacts:
    paths:
      - coverage/
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage/combined.xml
    expire_in: 1 week

test-acceptance:
  stage: integration
  image: ${CI_IMAGE_VERSIONED}
  extends:
    - .docker-dind
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: never
    - if: $CI_COMMIT_TAG
      when: never
    - !reference [.rules-code, rules]
  timeout: 30 minutes
  interruptible: true
  needs:
    - job: build-ci
      optional: true
    - job: build-test-image
  variables:
    HAPROXY_VERSION: "3.2"
    KIND_NODE_IMAGE: kindest/node:${KIND_NODE_VERSION}
    KEEP_NAMESPACE: "true"  # Preserve namespaces so after_script can collect logs on failure
  before_script:
    # Pull test image from registry and tag it for the acceptance tests
    # The Go test code handles kind cluster creation with DinD support
    - |
      TEST_IMAGE="${CI_REGISTRY_IMAGE}:ci-${CI_PIPELINE_ID}-haproxy${HAPROXY_VERSION}"
      docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
      docker pull ${TEST_IMAGE}
      docker tag ${TEST_IMAGE} haptic:test
  script:
    - go tool gotestsum --junitfile report-acceptance.xml --format testname -- -tags=acceptance -v -timeout 25m -run TestAllAcceptanceParallel ./tests/acceptance/...
  after_script:
    # Extract debug logs on failure for troubleshooting
    - |
      if [ "$CI_JOB_STATUS" = "failed" ]; then
        echo "Job failed - extracting debug logs..."
        mkdir -p debug-logs

        # Use the kubeconfig created by the acceptance tests
        export KUBECONFIG=/tmp/haproxy-test-kubeconfig

        # List all test namespaces (they have pattern test-*)
        for ns in $(kubectl get ns -o name 2>/dev/null | grep '^namespace/test-' | cut -d/ -f2); do
          echo "=== Namespace: $ns ===" >> debug-logs/test-namespaces.log

          # Controller pod logs with timestamps for correlation
          kubectl -n "$ns" logs -l app=haptic-controller --all-containers=true \
            --timestamps=true --since=10m \
            >> debug-logs/controller-$ns.log 2>&1 || true

          # Blocklist server logs (nginx) - critical for HTTP store tests
          kubectl -n "$ns" logs -l app=blocklist-server --all-containers=true \
            --timestamps=true --since=10m \
            >> debug-logs/blocklist-server-$ns.log 2>&1 || true

          # Pod status with IP addresses for debugging service routing
          kubectl -n "$ns" get pods -o wide >> debug-logs/pods-$ns.log 2>&1 || true

          # Events sorted by time with more detail
          kubectl -n "$ns" get events --sort-by=.lastTimestamp -o wide \
            >> debug-logs/events-$ns.log 2>&1 || true

          # Lease status for leader election debugging
          kubectl -n "$ns" get leases -o yaml \
            >> debug-logs/leases-$ns.log 2>&1 || true

          # ConfigMap content for HTTP store debugging
          kubectl -n "$ns" get configmaps -o yaml \
            >> debug-logs/configmaps-$ns.log 2>&1 || true
        done

        # Kind control plane logs for diagnosing API server/kube-proxy issues
        echo "Extracting Kind control plane logs..."

        # Use kind's built-in log export (most comprehensive)
        kind export logs debug-logs/kind-logs --name haproxy-test 2>/dev/null || true

        # Fallback: get kube-system pod logs directly
        kubectl -n kube-system get pods -o wide >> debug-logs/kube-system-pods.log 2>&1 || true
        kubectl -n kube-system logs -l component=kube-proxy --all-containers=true \
          --timestamps=true --since=10m >> debug-logs/kube-proxy.log 2>&1 || true
        kubectl -n kube-system logs -l k8s-app=kube-dns --all-containers=true \
          --timestamps=true --since=10m >> debug-logs/coredns.log 2>&1 || true

        # API server and etcd logs from docker (Kind runs as docker container)
        docker logs haproxy-test-control-plane >> debug-logs/kind-node.log 2>&1 || true

        echo "Debug logs extracted"
        ls -la debug-logs/ || true
      fi
    # Clean up cluster
    - kind delete cluster --name haproxy-test || true
  artifacts:
    reports:
      junit: report-acceptance.xml
    paths:
      - debug-logs/
    when: always
    expire_in: 1 week

.test-routes-base:
  stage: integration
  image: ${CI_IMAGE_VERSIONED}
  extends:
    - .docker-dind
  timeout: 25 minutes
  interruptible: true
  needs:
    - job: build-ci
      optional: true
    - job: build-test-image
  variables:
    # Controller namespace and release name - must match scripts/start-dev-env.sh defaults
    CTRL_NAMESPACE: haptic
    RELEASE_NAME: haptic
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: never
    - if: $CI_COMMIT_TAG
      when: never
    - changes:
        - "**/*.go"
        - go.mod
        - go.sum
        - charts/**
        - scripts/**
        - .gitlab-ci.yml
  before_script:
    - |
      # Pull pre-built test image from registry and tag for start-dev-env.sh
      TEST_IMAGE="${CI_REGISTRY_IMAGE}:ci-${CI_PIPELINE_ID}-haproxy${HAPROXY_VERSION}"
      docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
      docker pull ${TEST_IMAGE}
      docker tag ${TEST_IMAGE} haptic:dev
    - |
      # Pre-create kind cluster with DinD-compatible networking
      # start-dev-env.sh will detect the existing cluster and skip creation
      kind create cluster --name haptic-dev --image kindest/node:${KIND_NODE_VERSION} \
        --config .gitlab/ci/kind-config-dind.yaml --wait 120s
    - |
      # Fix kubeconfig to use "docker" hostname instead of 0.0.0.0
      mkdir -p ~/.kube
      kind get kubeconfig --name haptic-dev > ~/.kube/config
      sed -i 's|https://0\.0\.0\.0:|https://docker:|g' ~/.kube/config
    - |
      # Wait for API server to be ready
      for i in $(seq 1 30); do
        if kubectl get nodes &>/dev/null; then
          echo "API server is ready"
          break
        fi
        echo "Waiting for API server... (attempt $i/30)"
        sleep 2
      done
  script:
    - HAPROXY_VERSION=${HAPROXY_VERSION} ./scripts/start-dev-env.sh --skip-build --timeout 240
    - ./scripts/test-routes.sh
  after_script:
    # Extract debug logs on failure for troubleshooting
    - |
      if [ "$CI_JOB_STATUS" = "failed" ]; then
        echo "Job failed - extracting debug logs..."
        mkdir -p debug-logs

        # Controller logs - ALL pods (not just one from deployment)
        for pod in $(kubectl -n ${CTRL_NAMESPACE} get pods -l app.kubernetes.io/name=haptic -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
          echo "=== Controller: $pod ===" >> debug-logs/controller.log
          kubectl -n ${CTRL_NAMESPACE} logs "$pod" --all-containers=true >> debug-logs/controller.log 2>&1 || true
        done
        [ -f debug-logs/controller.log ] || echo "Failed to get controller logs" > debug-logs/controller.log

        # HAProxy and Dataplane logs - ALL pods
        for pod in $(kubectl -n ${CTRL_NAMESPACE} get pods -l app.kubernetes.io/component=loadbalancer -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
          echo "=== HAProxy: $pod ===" >> debug-logs/haproxy.log
          kubectl -n ${CTRL_NAMESPACE} logs "$pod" -c haproxy >> debug-logs/haproxy.log 2>&1 || true
          echo "=== Dataplane: $pod ===" >> debug-logs/dataplane.log
          kubectl -n ${CTRL_NAMESPACE} logs "$pod" -c dataplane >> debug-logs/dataplane.log 2>&1 || true
        done
        [ -f debug-logs/haproxy.log ] || echo "Failed to get HAProxy logs" > debug-logs/haproxy.log
        [ -f debug-logs/dataplane.log ] || echo "Failed to get dataplane logs" > debug-logs/dataplane.log

        # HAProxy configuration (useful for debugging routing issues)
        kubectl -n ${CTRL_NAMESPACE} exec deployment/${RELEASE_NAME}-haproxy -c haproxy -- \
          cat /etc/haproxy/haproxy.cfg > debug-logs/haproxy.cfg 2>&1 || echo "Failed to get HAProxy config"

        # Pod status summary
        kubectl get pods -A -o wide > debug-logs/pod-status.log 2>&1 || true

        # Events (useful for deployment issues)
        kubectl get events -n ${CTRL_NAMESPACE} --sort-by=.lastTimestamp \
          > debug-logs/events.log 2>&1 || true

        # Service details (including NodePorts) - critical for port connectivity issues
        kubectl get svc -n ${CTRL_NAMESPACE} -o yaml \
          > debug-logs/services.yaml 2>&1 || true

        # Network connectivity diagnostics
        {
          echo "=== Network Diagnostics ==="
          echo "DOCKER_HOST: ${DOCKER_HOST:-not set}"
          echo ""
          echo "=== Docker host resolution ==="
          DOCKER_HOSTNAME=$(echo "$DOCKER_HOST" | sed 's|tcp://||' | cut -d: -f1)
          getent hosts "$DOCKER_HOSTNAME" 2>&1 || echo "Failed to resolve docker hostname"
          echo ""
          echo "=== Port 30443 connectivity test ==="
          NODEPORT_IP=$(getent hosts "$DOCKER_HOSTNAME" | awk '{print $1}' | head -1)
          echo "Testing connection to ${NODEPORT_IP}:30443..."
          timeout 5 curl -vsk --max-time 5 "https://${NODEPORT_IP}:30443/" 2>&1 || echo "Connection failed"
          echo ""
          echo "=== Port 30080 connectivity test (reference) ==="
          echo "Testing connection to ${NODEPORT_IP}:30080..."
          timeout 5 curl -vs --max-time 5 -H "Host: echo.localdev.me" "http://${NODEPORT_IP}:30080/" 2>&1 | head -50 || echo "Connection failed"
        } > debug-logs/network-diagnostics.log 2>&1

        echo "Debug logs extracted to debug-logs/"
        ls -la debug-logs/
      fi
    # Clean up cluster
    - kind delete cluster --name haptic-dev || true
  artifacts:
    paths:
      - debug-logs/
    when: on_failure
    expire_in: 1 week

test-routes:
  extends:
    - .test-routes-base
    - .haproxy-version-matrix

# Helm chart default values test with cert-manager
# Verifies that the chart works out-of-the-box with default values when cert-manager is installed
test-helm-defaults:
  stage: integration
  image: ${CI_IMAGE}
  extends:
    - .docker-dind
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: never
    - if: $CI_COMMIT_TAG
      when: never
    - !reference [.rules-helm, rules]
  timeout: 15 minutes
  interruptible: true
  needs:
    - job: build-ci
      optional: true
    - job: build-test-image
  variables:
    # Unique cluster name - different from haproxy-test (integration) and haptic-dev (dev/routes)
    CLUSTER_NAME: helm-defaults
    NAMESPACE: haptic
    HAPROXY_VERSION: "3.2"
  before_script:
    - |
      # Pull pre-built test image from registry
      TEST_IMAGE="${CI_REGISTRY_IMAGE}:ci-${CI_PIPELINE_ID}-haproxy${HAPROXY_VERSION}"
      docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
      docker pull ${TEST_IMAGE}
    - |
      # Pre-create kind cluster with DinD-compatible networking
      kind create cluster --name ${CLUSTER_NAME} --config .gitlab/ci/kind-config-dind.yaml --wait 120s
    - |
      # Fix kubeconfig to use "docker" hostname instead of 0.0.0.0
      mkdir -p ~/.kube
      kind get kubeconfig --name ${CLUSTER_NAME} > ~/.kube/config
      sed -i 's|https://0\.0\.0\.0:|https://docker:|g' ~/.kube/config
    - |
      # Wait for API server to be ready
      for i in $(seq 1 30); do
        if kubectl get nodes &>/dev/null; then
          echo "API server is ready"
          break
        fi
        echo "Waiting for API server... (attempt $i/30)"
        sleep 2
      done
    - |
      # Load test image into kind cluster
      kind load docker-image ${TEST_IMAGE} --name ${CLUSTER_NAME}
  script:
    - ./scripts/test-helm-defaults.sh --image "${TEST_IMAGE}"
  after_script:
    - |
      if [ "$CI_JOB_STATUS" = "failed" ]; then
        echo "Job failed - extracting debug logs..."
        mkdir -p debug-logs

        echo "=== Pod Status ===" > debug-logs/pods.log
        kubectl get pods -A -o wide >> debug-logs/pods.log 2>&1 || true

        echo "=== Events ===" > debug-logs/events.log
        kubectl get events -A --sort-by='.lastTimestamp' >> debug-logs/events.log 2>&1 || true

        echo "=== Controller Logs ===" > debug-logs/controller.log
        kubectl logs -n ${NAMESPACE} -l app.kubernetes.io/component=controller --tail=200 >> debug-logs/controller.log 2>&1 || true

        echo "=== HAProxy Logs ===" > debug-logs/haproxy.log
        kubectl logs -n ${NAMESPACE} -l app.kubernetes.io/component=loadbalancer --tail=200 >> debug-logs/haproxy.log 2>&1 || true

        echo "=== Certificates ===" > debug-logs/certificates.log
        kubectl get certificates -A -o wide >> debug-logs/certificates.log 2>&1 || true
        kubectl describe certificates -n ${NAMESPACE} >> debug-logs/certificates.log 2>&1 || true

        echo "=== Issuers ===" > debug-logs/issuers.log
        kubectl get issuers -A -o wide >> debug-logs/issuers.log 2>&1 || true

        echo "=== TLS Secrets ===" > debug-logs/secrets.log
        kubectl get secrets -A --field-selector type=kubernetes.io/tls >> debug-logs/secrets.log 2>&1 || true

        echo "Debug logs extracted to debug-logs/"
        ls -la debug-logs/
      fi
    - kind delete cluster --name ${CLUSTER_NAME} || true
  artifacts:
    paths:
      - debug-logs/
    when: on_failure
    expire_in: 1 week
  tags:
    - saas-linux-large-amd64

# =============================================================================
# Deploy Stage
# =============================================================================

# =============================================================================
# Controller Release (triggered by controller-v* tags)
# =============================================================================

# Build Go binaries with GoReleaser and create GitLab release
release-controller-binaries:
  stage: deploy
  image: ${CI_IMAGE}
  tags:
    - saas-linux-large-amd64
  needs:
    - job: build-ci
      optional: true
  variables:
    GIT_DEPTH: 0
    GITLAB_TOKEN: ${CI_JOB_TOKEN}
  rules:
    - if: $CI_COMMIT_TAG =~ /^haptic-controller-v.*/
  script:
    # Extract version from tag (haptic-controller-v0.1.0 -> v0.1.0)
    - export VERSION=${CI_COMMIT_TAG#haptic-controller-}
    # Extract release notes from CHANGELOG.md
    - |
      sed -n "/^## \[${VERSION#v}\]/,/^## \[/p" CHANGELOG.md | head -n -1 > /tmp/release-notes.md || true
      if [ ! -s /tmp/release-notes.md ]; then
        echo "Release ${VERSION}" > /tmp/release-notes.md
      fi
    # Build binaries and create GitLab release
    - goreleaser release --clean --release-notes /tmp/release-notes.md

# Build Docker images for each HAProxy version
release-controller-images:
  stage: deploy
  extends:
    - .docker-dind
  image: docker:${DOCKER_VERSION}
  tags:
    - saas-linux-large-amd64
  needs:
    - release-controller-binaries
  rules:
    - if: $CI_COMMIT_TAG =~ /^haptic-controller-v.*/
  variables:
    DEFAULT_HAPROXY: "3.2"
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker buildx create --use --name multiarch
    - apk add --no-cache crane cosign curl
    # Install syft for SBOM generation
    - curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin
  script:
    - export VERSION=${CI_COMMIT_TAG#haptic-controller-}
    # Check if this is a stable release (no -alpha, -beta, -rc suffix)
    - |
      if echo "$VERSION" | grep -qE '-(alpha|beta|rc)'; then
        IS_STABLE=false
      else
        IS_STABLE=true
      fi
    # Build images for each HAProxy version
    - |
      for HAPROXY_VERSION in 3.0 3.1 3.2; do
        echo "Building for HAProxy ${HAPROXY_VERSION}..."
        IMAGE_TAG="${CI_REGISTRY_IMAGE}:${VERSION}-haproxy${HAPROXY_VERSION}"

        # Build and push multi-arch image
        docker buildx build \
          --platform linux/amd64,linux/arm64,linux/arm/v7 \
          --build-arg HAPROXY_VERSION=${HAPROXY_VERSION} \
          --build-arg GIT_COMMIT=${CI_COMMIT_SHA} \
          --build-arg GIT_TAG=${VERSION} \
          -t $IMAGE_TAG \
          --push .

        # Sign image with Cosign (keyless)
        cosign sign --yes $IMAGE_TAG

        # Generate and attach SBOM as attestation
        echo "Generating SBOM for ${IMAGE_TAG}..."
        syft $IMAGE_TAG -o spdx-json > sbom-haproxy${HAPROXY_VERSION}.spdx.json
        cosign attest --predicate sbom-haproxy${HAPROXY_VERSION}.spdx.json --type spdxjson --yes $IMAGE_TAG

        # Create default tag for latest HAProxy (stable releases only)
        if [ "$HAPROXY_VERSION" = "$DEFAULT_HAPROXY" ] && [ "$IS_STABLE" = "true" ]; then
          crane copy $IMAGE_TAG ${CI_REGISTRY_IMAGE}:${VERSION}
          cosign sign --yes ${CI_REGISTRY_IMAGE}:${VERSION}
        fi

        # Tag 'latest' only for stable releases
        if [ "$IS_STABLE" = "true" ]; then
          crane copy $IMAGE_TAG ${CI_REGISTRY_IMAGE}:latest-haproxy${HAPROXY_VERSION}
          cosign sign --yes ${CI_REGISTRY_IMAGE}:latest-haproxy${HAPROXY_VERSION}

          # Default 'latest' tag for latest HAProxy
          if [ "$HAPROXY_VERSION" = "$DEFAULT_HAPROXY" ]; then
            crane copy $IMAGE_TAG ${CI_REGISTRY_IMAGE}:latest
            cosign sign --yes ${CI_REGISTRY_IMAGE}:latest
          fi
        fi
      done

# =============================================================================
# Chart Release (triggered by haptic-chart-v* tags)
# =============================================================================

release-chart:
  stage: deploy
  image: ${CI_IMAGE}
  tags:
    - saas-linux-medium-amd64
  needs:
    - job: build-ci
      optional: true
  rules:
    - if: $CI_COMMIT_TAG =~ /^haptic-chart-v.*/
  before_script:
    - helm registry login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    # Extract version from tag (haptic-chart-v0.1.0 -> v0.1.0)
    - export VERSION=${CI_COMMIT_TAG#haptic-chart-}
    # Extract release notes from chart CHANGELOG.md
    - |
      sed -n "/^## \[${VERSION#v}\]/,/^## \[/p" charts/haptic/CHANGELOG.md | head -n -1 > .release-notes.md || true
      if [ ! -s .release-notes.md ]; then
        echo "Helm Chart Release ${VERSION}" > .release-notes.md
      fi
    # Package and push chart to OCI registry
    - helm package charts/haptic --version $VERSION
    - |
      helm push haptic-$VERSION.tgz oci://${CI_REGISTRY}/haproxy-template-ic/haproxy-template-ingress-controller/charts 2>&1 | tee push-output.txt
      CHART_DIGEST=$(grep 'Digest:' push-output.txt | awk '{print $2}')
      # Sign the OCI artifact using digest (cosign doesn't support oci:// prefix)
      cosign sign --yes ${CI_REGISTRY}/haproxy-template-ic/haproxy-template-ingress-controller/charts/haptic@${CHART_DIGEST}
    # Create GitLab release
    - |
      RELEASE_NAME="Helm Chart ${VERSION}"
      if echo "$VERSION" | grep -qE '-(alpha|beta|rc)\.'; then
        RELEASE_NAME="Helm Chart ${VERSION} (Pre-release)"
      fi
      curl --fail-with-body --header "JOB-TOKEN: ${CI_JOB_TOKEN}" \
           --header "Content-Type: application/json" \
           --data "{
             \"name\": \"${RELEASE_NAME}\",
             \"tag_name\": \"${CI_COMMIT_TAG}\",
             \"description\": $(cat .release-notes.md | jq -Rs .)
           }" \
           --request POST \
           "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/releases"

# =============================================================================
# Release Documentation (triggered by release tags)
# =============================================================================

# Trigger versioned documentation build for controller releases
trigger-docs-controller-release:
  stage: deploy
  needs:
    - release-controller-binaries
  rules:
    - if: $CI_COMMIT_TAG =~ /^haptic-controller-v.*/
  inherit:
    variables: false
  variables:
    DOC_VERSION: ${CI_COMMIT_TAG#haptic-controller-}
  trigger:
    project: haproxy-template-ic/haproxy-template-ic.gitlab.io
    branch: main
    strategy: depend

# Trigger versioned documentation build for chart releases
trigger-docs-chart-release:
  stage: deploy
  needs:
    - release-chart
  rules:
    - if: $CI_COMMIT_TAG =~ /^haptic-chart-v.*/
  inherit:
    variables: false
  variables:
    DOC_VERSION: ${CI_COMMIT_TAG#haptic-chart-}
  trigger:
    project: haproxy-template-ic/haproxy-template-ic.gitlab.io
    branch: main
    strategy: depend

# =============================================================================
# MR Documentation Preview
# =============================================================================

# MR documentation preview with versioned docs
# Uses shared deployment script from pages repo for consistency with production
pages-preview:
  stage: deploy
  image: ${CI_REGISTRY_IMAGE}/ci/python-docs:latest
  tags:
    - saas-linux-small-amd64
  needs:
    - job: build-python-docs
      optional: true
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      changes: &pages-preview-changes
        - docs/**
        - charts/**/docs/**
        - charts/**/mkdocs.yml
  script:
    - |
      # Clone pages repo to get deployment script and existing content
      git clone --depth 1 https://gitlab.com/haproxy-template-ic/haproxy-template-ic.gitlab.io.git pages-repo
    - |
      # Use shared deployment script (same as production)
      chmod +x pages-repo/scripts/deploy-docs.sh
      pages-repo/scripts/deploy-docs.sh dev . ./public
    - echo "Preview available at ${CI_PAGES_URL}/"
  pages:
    path_prefix: "mr-$CI_MERGE_REQUEST_IID"
    expire_in: never  # Cleaned up automatically when MR closes
  artifacts:
    paths:
      - public
  environment:
    name: docs/mr-$CI_MERGE_REQUEST_IID
    url: $CI_PAGES_URL/
    on_stop: pages-preview-cleanup
    auto_stop_in: 1 week

# Cleanup job for MR preview (runs when MR is closed/merged)
pages-preview-cleanup:
  stage: deploy
  image: alpine:latest
  tags:
    - saas-linux-small-amd64
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: manual
      allow_failure: true
      changes: *pages-preview-changes
  script:
    - echo "MR preview environment stopped"
  environment:
    name: docs/mr-$CI_MERGE_REQUEST_IID
    action: stop

# Trigger pages project to build and deploy docs to group-level pages
trigger-pages:
  stage: deploy
  needs: []
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      changes:
        - docs/**
        - charts/**/docs/**
        - charts/**/mkdocs.yml
  inherit:
    variables: false
  trigger:
    project: haproxy-template-ic/haproxy-template-ic.gitlab.io
    branch: main
    strategy: depend

# =============================================================================
# Automatic Release Tagging (triggered when VERSION or Chart.yaml changes)
# =============================================================================
# These jobs automatically create release tags when version files change on main.
# This eliminates manual tagging after MR merge - just update VERSION or Chart.yaml,
# merge to main, and CI creates the tag and triggers the release pipeline.

# Create controller release tag when VERSION file changes on main
create-controller-release-tag:
  stage: deploy
  image: ${CI_IMAGE}
  tags:
    - saas-linux-small-amd64
  needs:
    - job: build-ci
      optional: true
  rules:
    - if: $CI_COMMIT_TAG
      when: never  # Don't run on tag pipelines
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  script:
    - VERSION=$(cat VERSION)
    - TAG="haptic-controller-v${VERSION}"
    # Check if tag already exists (idempotency)
    - |
      if git ls-remote --tags origin | grep -q "refs/tags/${TAG}$"; then
        echo "Tag ${TAG} already exists, skipping"
        exit 0
      fi
    # Create and push the tag
    - git config user.email "ci@gitlab.com"
    - git config user.name "GitLab CI"
    - git tag -a "${TAG}" -m "Controller release v${VERSION}"
    - git push "https://gitlab-ci-token:${CI_JOB_TOKEN}@${CI_SERVER_HOST}/${CI_PROJECT_PATH}.git" "${TAG}"
    # Trigger release pipeline for the new tag
    - |
      curl --fail-with-body --request POST \
        --form "token=${CI_JOB_TOKEN}" \
        --form "ref=${TAG}" \
        "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/trigger/pipeline"
    - echo "Created and pushed tag ${TAG}, release pipeline triggered"

# Create chart release tag when Chart.yaml version changes on main
create-chart-release-tag:
  stage: deploy
  image: ${CI_IMAGE}
  tags:
    - saas-linux-small-amd64
  needs:
    - job: build-ci
      optional: true
  rules:
    - if: $CI_COMMIT_TAG
      when: never  # Don't run on tag pipelines
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  script:
    - VERSION=$(yq '.version' charts/haptic/Chart.yaml)
    - TAG="haptic-chart-v${VERSION}"
    # Check if tag already exists (idempotency)
    - |
      if git ls-remote --tags origin | grep -q "refs/tags/${TAG}$"; then
        echo "Tag ${TAG} already exists, skipping"
        exit 0
      fi
    # Create and push the tag
    - git config user.email "ci@gitlab.com"
    - git config user.name "GitLab CI"
    - git tag -a "${TAG}" -m "Chart release v${VERSION}"
    - git push "https://gitlab-ci-token:${CI_JOB_TOKEN}@${CI_SERVER_HOST}/${CI_PROJECT_PATH}.git" "${TAG}"
    # Trigger release pipeline for the new tag
    - |
      curl --fail-with-body --request POST \
        --form "token=${CI_JOB_TOKEN}" \
        --form "ref=${TAG}" \
        "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/trigger/pipeline"
    - echo "Created and pushed tag ${TAG}, release pipeline triggered"
